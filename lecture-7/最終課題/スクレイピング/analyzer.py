"""
æœˆåˆ¥è¦³å…‰ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ„ãƒ¼ãƒ« + ä»®èª¬æ¤œè¨¼
"""

import sqlite3
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
import japanize_matplotlib
from pathlib import Path
import warnings

warnings.filterwarnings('ignore')

# é™¤å¤–ã™ã‚‹é›†è¨ˆã‚«ãƒ†ã‚´ãƒª
EXCLUDE_CATEGORIES = ['å®Ÿå®¿æ³Šè€…', 'ç·æ•°', 'å¤–å›½äºº']

def connect_db():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š"""
    script_dir = Path(__file__).parent
    db_path = script_dir / 'tourism_data.db'
    
    if not db_path.exists():
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {db_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        exit(1)
    
    conn = sqlite3.connect(str(db_path))
    
    # ãƒ‡ãƒ¼ã‚¿æ•°ç¢ºèª
    placeholders = ','.join('?' * len(EXCLUDE_CATEGORIES))
    cursor = conn.execute(
        f'SELECT COUNT(DISTINCT month) FROM tourism_data WHERE nationality NOT IN ({placeholders})', 
        EXCLUDE_CATEGORIES
    )
    month_count = cursor.fetchone()[0]
    
    print(f"ğŸ“‚ DB ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: {db_path}")
    print(f"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šæˆåŠŸ: {month_count} æœˆåˆ†ã®ãƒ‡ãƒ¼ã‚¿\n")
    
    return conn

def analyze_monthly_summary(conn):
    """æœˆåˆ¥ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼"""
    print("="*60)
    print("ğŸ“… æœˆåˆ¥ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼")
    print("="*60 + "\n")
    
    placeholders = ','.join('?' * len(EXCLUDE_CATEGORIES))
    query = f'''
        SELECT 
            CASE 
                WHEN month = 0 THEN 'å¹´è¨ˆ'
                ELSE printf('%2dæœˆ', month)
            END as month_label,
            COUNT(DISTINCT prefecture) as pref_count,
            COUNT(DISTINCT nationality) as nat_count,
            SUM(value) as total_stays
        FROM tourism_data
        WHERE nationality NOT IN ({placeholders})
        GROUP BY month
        ORDER BY month
    '''
    
    df = pd.read_sql(query, conn, params=EXCLUDE_CATEGORIES)
    
    print(f"{'æœˆ':^8} {'ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°':>10} {'éƒ½é“åºœçœŒ':>8} {'å›½ç±æ•°':>8} {'ç·å®¿æ³Šè€…æ•°':>18}")
    print("-" * 60)
    
    for _, row in df.iterrows():
        print(f"{row['month_label']:^8} {row['pref_count']*row['nat_count']:>10} "
              f"{row['pref_count']:>8} {row['nat_count']:>8} {row['total_stays']:>18,}")

def analyze_monthly_trend(conn):
    """æœˆåˆ¥æ¨ç§»åˆ†æ"""
    print("\n" + "="*60)
    print("ğŸ“Š æœˆåˆ¥æ¨ç§»åˆ†æ")
    print("="*60 + "\n")
    
    placeholders = ','.join('?' * len(EXCLUDE_CATEGORIES))
    query = f'''
        SELECT month, SUM(value) as total
        FROM tourism_data
        WHERE nationality NOT IN ({placeholders}) AND month > 0
        GROUP BY month
        ORDER BY month
    '''
    
    df = pd.read_sql(query, conn, params=EXCLUDE_CATEGORIES)
    
    print("ã€æœˆåˆ¥å¤–å›½äººå®¿æ³Šè€…æ•°æ¨ç§»ã€‘")
    for _, row in df.iterrows():
        print(f"  {int(row['month']):>3}æœˆ: {row['total']:>14,} äººæ³Š")
    
    # ã‚°ãƒ©ãƒ•ä½œæˆ
    fig, ax = plt.subplots(figsize=(12, 6))
    
    months = [f"{int(m)}æœˆ" for m in df['month']]
    values = df['total'].values
    
    colors = ['#FF6B6B' if v == max(values) else '#4ECDC4' if v == min(values) else '#95E1D3' 
              for v in values]
    
    bars = ax.bar(months, values, color=colors, edgecolor='black', linewidth=0.7)
    
    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
                f'{int(height/10000)}ä¸‡',
                ha='center', va='bottom', fontsize=9)
    
    ax.set_xlabel('æœˆ', fontsize=12)
    ax.set_ylabel('å®¿æ³Šè€…æ•°ï¼ˆäººæ³Šï¼‰', fontsize=12)
    ax.set_title('æœˆåˆ¥å¤–å›½äººå®¿æ³Šè€…æ•°æ¨ç§»', fontsize=14, fontweight='bold', pad=20)
    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x/1000000)}M'))
    ax.grid(axis='y', alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('output_monthly_trend.png', dpi=150, bbox_inches='tight')
    plt.close()
    
    print("\nğŸ’¾ ä¿å­˜: output_monthly_trend.png")

def analyze_monthly_prefecture_ranking(conn):
    """æœˆåˆ¥éƒ½é“åºœçœŒãƒ©ãƒ³ã‚­ãƒ³ã‚°æ¨ç§»"""
    print("\n" + "="*60)
    print("ğŸ“Š æœˆåˆ¥éƒ½é“åºœçœŒãƒ©ãƒ³ã‚­ãƒ³ã‚°æ¨ç§»")
    print("="*60 + "\n")
    
    print("ã€å„æœˆã®ãƒˆãƒƒãƒ—5éƒ½é“åºœçœŒã€‘\n")
    
    placeholders = ','.join('?' * len(EXCLUDE_CATEGORIES))
    
    # æœˆã”ã¨ã®ãƒˆãƒƒãƒ—5
    for month in range(1, 13):
        params = EXCLUDE_CATEGORIES + [month]
        query = f'''
            SELECT prefecture, SUM(value) as total
            FROM tourism_data
            WHERE nationality NOT IN ({placeholders}) AND month = ?
            GROUP BY prefecture
            ORDER BY total DESC
            LIMIT 5
        '''
        df = pd.read_sql(query, conn, params=params)
        
        print(f"  {month}æœˆ:")
        for i, row in enumerate(df.itertuples(), 1):
            print(f"    {i}. {row.prefecture:<10} {row.total:>14,} äººæ³Š")
        print()
    
    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ä½œæˆ
    print("ã€æœˆåˆ¥Ã—éƒ½é“åºœçœŒ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ä½œæˆä¸­...ã€‘\n")
    
    query = f'''
        SELECT month, prefecture, SUM(value) as total
        FROM tourism_data
        WHERE nationality NOT IN ({placeholders}) AND month > 0
        GROUP BY month, prefecture
    '''
    df = pd.read_sql(query, conn, params=EXCLUDE_CATEGORIES)
    
    # ãƒˆãƒƒãƒ—15éƒ½é“åºœçœŒã‚’æŠ½å‡º
    top_prefs = df.groupby('prefecture')['total'].sum().nlargest(15).index
    df_filtered = df[df['prefecture'].isin(top_prefs)]
    
    # ãƒ”ãƒœãƒƒãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
    pivot = df_filtered.pivot(index='prefecture', columns='month', values='total')
    pivot = pivot.div(1000000)  # ç™¾ä¸‡äººæ³Šå˜ä½
    
    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
    fig, ax = plt.subplots(figsize=(14, 8))
    sns.heatmap(pivot, annot=True, fmt='.1f', cmap='YlOrRd', 
                linewidths=0.5, cbar_kws={'label': 'å®¿æ³Šè€…æ•°ï¼ˆç™¾ä¸‡äººæ³Šï¼‰'})
    
    ax.set_xlabel('æœˆ', fontsize=12)
    ax.set_ylabel('éƒ½é“åºœçœŒ', fontsize=12)
    ax.set_title('æœˆåˆ¥Ã—éƒ½é“åºœçœŒ å®¿æ³Šè€…æ•°ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ— (ãƒˆãƒƒãƒ—15)', 
                 fontsize=13, fontweight='bold', pad=15)
    
    plt.tight_layout()
    plt.savefig('output_monthly_prefecture_heatmap.png', dpi=150, bbox_inches='tight')
    plt.close()
    
    print("ğŸ’¾ ä¿å­˜: output_monthly_prefecture_heatmap.png")

def analyze_specific_month(conn, target_month=12):
    """ç‰¹å®šæœˆã®è©³ç´°åˆ†æ"""
    print("\n" + "="*60)
    print(f"ğŸ“Š {target_month}æœˆã®éƒ½é“åºœçœŒåˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    print("="*60 + "\n")
    
    placeholders = ','.join('?' * len(EXCLUDE_CATEGORIES))
    params = EXCLUDE_CATEGORIES + [target_month]
    
    query = f'''
        SELECT prefecture, SUM(value) as total
        FROM tourism_data
        WHERE nationality NOT IN ({placeholders}) AND month = ?
        GROUP BY prefecture
        ORDER BY total DESC
        LIMIT 20
    '''
    
    df = pd.read_sql(query, conn, params=params)
    total_sum = df['total'].sum()
    df['share'] = df['total'] / total_sum * 100
    
    print(f"ã€{target_month}æœˆ éƒ½é“åºœçœŒåˆ¥ãƒˆãƒƒãƒ—20ã€‘")
    for i, row in enumerate(df.itertuples(), 1):
        print(f"  {i:>2}. {row.prefecture:<10} {row.total:>18,} äººæ³Š ({row.share:>5.2f}%)")
    
    # ã‚°ãƒ©ãƒ•ä½œæˆ
    fig, ax = plt.subplots(figsize=(12, 8))
    
    colors = plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(df)))
    bars = ax.barh(df['prefecture'][::-1], df['total'][::-1], color=colors[::-1], 
                   edgecolor='black', linewidth=0.5)
    
    for i, bar in enumerate(bars):
        width = bar.get_width()
        ax.text(width, bar.get_y() + bar.get_height()/2,
                f'{int(width/10000)}ä¸‡ ({df["share"].iloc[::-1].iloc[i]:.1f}%)',
                ha='left', va='center', fontsize=9, fontweight='bold')
    
    ax.set_xlabel('å®¿æ³Šè€…æ•°ï¼ˆäººæ³Šï¼‰', fontsize=12)
    ax.set_ylabel('éƒ½é“åºœçœŒ', fontsize=12)
    ax.set_title(f'{target_month}æœˆ éƒ½é“åºœçœŒåˆ¥å¤–å›½äººå®¿æ³Šè€…æ•°ãƒ©ãƒ³ã‚­ãƒ³ã‚°', 
                 fontsize=13, fontweight='bold', pad=15)
    ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x/1000000)}M'))
    
    plt.tight_layout()
    plt.savefig(f'output_month{target_month}_prefectures.png', dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"\nğŸ’¾ ä¿å­˜: output_month{target_month}_prefectures.png")
    
    # å›½ç±åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    print("\n" + "="*60)
    print(f"ğŸ“Š {target_month}æœˆã®å›½ç±åˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    print("="*60 + "\n")
    
    query = f'''
        SELECT nationality, SUM(value) as total
        FROM tourism_data
        WHERE nationality NOT IN ({placeholders}) AND month = ?
        GROUP BY nationality
        ORDER BY total DESC
    '''
    
    df_nat = pd.read_sql(query, conn, params=params)
    total_sum_nat = df_nat['total'].sum()
    df_nat['share'] = df_nat['total'] / total_sum_nat * 100
    
    print(f"ã€{target_month}æœˆ å›½ç±åˆ¥ãƒˆãƒƒãƒ—15ã€‘")
    for i, row in enumerate(df_nat.itertuples(), 1):
        print(f"  {i:>2}. {row.nationality:<15} {row.total:>18,} äººæ³Š ({row.share:>5.2f}%)")
    
    # ã‚°ãƒ©ãƒ•ä½œæˆ
    fig, ax = plt.subplots(figsize=(10, 8))
    
    colors_nat = plt.cm.Spectral(np.linspace(0, 1, len(df_nat)))
    bars = ax.barh(df_nat['nationality'][::-1], df_nat['total'][::-1], 
                   color=colors_nat[::-1], edgecolor='black', linewidth=0.5)
    
    for i, bar in enumerate(bars):
        width = bar.get_width()
        ax.text(width, bar.get_y() + bar.get_height()/2,
                f'{int(width/10000)}ä¸‡ ({df_nat["share"].iloc[::-1].iloc[i]:.1f}%)',
                ha='left', va='center', fontsize=9, fontweight='bold')
    
    ax.set_xlabel('å®¿æ³Šè€…æ•°ï¼ˆäººæ³Šï¼‰', fontsize=12)
    ax.set_ylabel('å›½ç±', fontsize=12)
    ax.set_title(f'{target_month}æœˆ å›½ç±åˆ¥å¤–å›½äººå®¿æ³Šè€…æ•°ãƒ©ãƒ³ã‚­ãƒ³ã‚°', 
                 fontsize=13, fontweight='bold', pad=15)
    ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x/1000000)}M'))
    
    plt.tight_layout()
    plt.savefig(f'output_month{target_month}_nationalities.png', dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"\nğŸ’¾ ä¿å­˜: output_month{target_month}_nationalities.png")

def analyze_prefecture_trend(conn, prefecture):
    """éƒ½é“åºœçœŒåˆ¥ã®æœˆåˆ¥æ¨ç§»"""
    print("\n" + "="*60)
    print(f"ğŸ“Š {prefecture}ã®æœˆåˆ¥æ¨ç§»")
    print("="*60 + "\n")
    
    placeholders = ','.join('?' * len(EXCLUDE_CATEGORIES))
    params = EXCLUDE_CATEGORIES + [prefecture]
    
    query = f'''
        SELECT month, SUM(value) as total
        FROM tourism_data
        WHERE nationality NOT IN ({placeholders}) AND prefecture = ? AND month > 0
        GROUP BY month
        ORDER BY month
    '''
    
    df = pd.read_sql(query, conn, params=params)
    
    print(f"ã€{prefecture} æœˆåˆ¥å¤–å›½äººå®¿æ³Šè€…æ•°ã€‘")
    for _, row in df.iterrows():
        print(f"  {int(row['month']):>3}æœˆ: {row['total']:>14,} äººæ³Š")
    
    # ã‚°ãƒ©ãƒ•ä½œæˆ
    fig, ax = plt.subplots(figsize=(12, 6))
    
    months = [f"{int(m)}æœˆ" for m in df['month']]
    values = df['total'].values
    
    ax.plot(months, values, marker='o', linewidth=2.5, markersize=8, 
            color='#3498db', markerfacecolor='#e74c3c')
    ax.fill_between(range(len(months)), values, alpha=0.3, color='#3498db')
    
    for i, v in enumerate(values):
        ax.text(i, v, f'{int(v/10000)}ä¸‡', ha='center', va='bottom', fontsize=9)
    
    ax.set_xlabel('æœˆ', fontsize=12)
    ax.set_ylabel('å®¿æ³Šè€…æ•°ï¼ˆäººæ³Šï¼‰', fontsize=12)
    ax.set_title(f'{prefecture} æœˆåˆ¥å¤–å›½äººå®¿æ³Šè€…æ•°æ¨ç§»', fontsize=14, fontweight='bold', pad=20)
    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x/1000000)}M'))
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(f'output_{prefecture}_monthly_trend.png', dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"\nğŸ’¾ ä¿å­˜: output_{prefecture}_monthly_trend.png")


# ==========================================
# ä»®èª¬1: å­£ç¯€å¤‰å‹•ã¨åœ°åŸŸç‰¹æ€§ã®ç›¸é–¢åˆ†æ
# ==========================================

def hypothesis1_seasonal_correlation(conn):
    """ä»®èª¬1: åŒ—æµ·é“ã¨æ²–ç¸„ã®å­£ç¯€ç›¸é–¢åˆ†æ"""
    
    print("\n" + "="*70)
    print("ğŸ”¬ ä»®èª¬1: å­£ç¯€å¤‰å‹•ã¨åœ°åŸŸç‰¹æ€§ã®ç›¸é–¢åˆ†æ")
    print("="*70)
    
    # ãƒ‡ãƒ¼ã‚¿å–å¾—
    placeholders = ','.join('?' * len(EXCLUDE_CATEGORIES))
    query = f'''
        SELECT month, 
               SUM(CASE WHEN prefecture='åŒ—æµ·é“' THEN value ELSE 0 END) as hokkaido,
               SUM(CASE WHEN prefecture='æ²–ç¸„çœŒ' THEN value ELSE 0 END) as okinawa,
               SUM(CASE WHEN prefecture='æ±äº¬éƒ½' THEN value ELSE 0 END) as tokyo
        FROM tourism_data
        WHERE nationality NOT IN ({placeholders}) AND month > 0
        GROUP BY month
        ORDER BY month
    '''
    df = pd.read_sql(query, conn, params=EXCLUDE_CATEGORIES)
    
    # ç›¸é–¢ä¿‚æ•°è¨ˆç®—
    corr_hokkaido_okinawa = df['hokkaido'].corr(df['okinawa'])
    corr_tokyo_hokkaido = df['tokyo'].corr(df['hokkaido'])
    corr_tokyo_okinawa = df['tokyo'].corr(df['okinawa'])
    
    print(f"\nã€åœ°åŸŸé–“ã®å­£ç¯€ç›¸é–¢ä¿‚æ•°ã€‘")
    print(f"  åŒ—æµ·é“ â‡” æ²–ç¸„çœŒ: {corr_hokkaido_okinawa:6.3f} {'(é€†ç›¸é–¢)' if corr_hokkaido_okinawa < 0 else '(æ­£ç›¸é–¢)'}")
    print(f"  æ±äº¬éƒ½ â‡” åŒ—æµ·é“: {corr_tokyo_hokkaido:6.3f}")
    print(f"  æ±äº¬éƒ½ â‡” æ²–ç¸„çœŒ: {corr_tokyo_okinawa:6.3f}")
    
    # å¤‰å‹•ä¿‚æ•°(CV)è¨ˆç®—
    cv_hokkaido = df['hokkaido'].std() / df['hokkaido'].mean()
    cv_okinawa = df['okinawa'].std() / df['okinawa'].mean()
    cv_tokyo = df['tokyo'].std() / df['tokyo'].mean()
    
    print(f"\nã€å­£ç¯€å¤‰å‹•ãƒªã‚¹ã‚¯ (å¤‰å‹•ä¿‚æ•°)ã€‘")
    print(f"  åŒ—æµ·é“: {cv_hokkaido:.3f} (æœ€å¤§/æœ€å°æ¯”: {df['hokkaido'].max()/df['hokkaido'].min():.2f}å€)")
    print(f"  æ²–ç¸„çœŒ: {cv_okinawa:.3f} (æœ€å¤§/æœ€å°æ¯”: {df['okinawa'].max()/df['okinawa'].min():.2f}å€)")
    print(f"  æ±äº¬éƒ½: {cv_tokyo:.3f} (æœ€å¤§/æœ€å°æ¯”: {df['tokyo'].max()/df['tokyo'].min():.2f}å€)")
    
    # çµ±è¨ˆçš„æ¤œå®š
    from scipy.stats import pearsonr
    r, p_value = pearsonr(df['hokkaido'], df['okinawa'])
    print(f"\nã€çµ±è¨ˆçš„æœ‰æ„æ€§ã€‘")
    print(f"  på€¤: {p_value:.4f} {'(æœ‰æ„)' if p_value < 0.05 else '(éæœ‰æ„)'}")
    
    # ã‚°ãƒ©ãƒ•1: æ•£å¸ƒå›³
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # åŒ—æµ·é“ vs æ²–ç¸„
    axes[0].scatter(df['hokkaido'], df['okinawa'], s=100, alpha=0.6, c=df['month'], cmap='coolwarm')
    axes[0].plot(df['hokkaido'], np.poly1d(np.polyfit(df['hokkaido'], df['okinawa'], 1))(df['hokkaido']), 
                 'r--', linewidth=2, label=f'r={corr_hokkaido_okinawa:.3f}')
    axes[0].set_xlabel('åŒ—æµ·é“ å®¿æ³Šæ•°ï¼ˆäººæ³Šï¼‰', fontsize=11)
    axes[0].set_ylabel('æ²–ç¸„çœŒ å®¿æ³Šæ•°ï¼ˆäººæ³Šï¼‰', fontsize=11)
    axes[0].set_title('ä»®èª¬1: åŒ—æµ·é“ã¨æ²–ç¸„ã®å­£ç¯€ç›¸é–¢', fontsize=12, fontweight='bold')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)
    
    # æœˆåˆ¥ãƒ©ãƒ™ãƒ«è¿½åŠ 
    for i, row in df.iterrows():
        axes[0].annotate(f"{int(row['month'])}æœˆ", (row['hokkaido'], row['okinawa']), 
                        fontsize=8, alpha=0.7)
    
    # æ±äº¬ vs åŒ—æµ·é“
    axes[1].scatter(df['tokyo'], df['hokkaido'], s=100, alpha=0.6, c=df['month'], cmap='viridis')
    axes[1].plot(df['tokyo'], np.poly1d(np.polyfit(df['tokyo'], df['hokkaido'], 1))(df['tokyo']), 
                 'b--', linewidth=2, label=f'r={corr_tokyo_hokkaido:.3f}')
    axes[1].set_xlabel('æ±äº¬éƒ½ å®¿æ³Šæ•°ï¼ˆäººæ³Šï¼‰', fontsize=11)
    axes[1].set_ylabel('åŒ—æµ·é“ å®¿æ³Šæ•°ï¼ˆäººæ³Šï¼‰', fontsize=11)
    axes[1].set_title('æ±äº¬éƒ½ã¨åŒ—æµ·é“ã®å­£ç¯€ç›¸é–¢', fontsize=12, fontweight='bold')
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('hypothesis1_seasonal_correlation.png', dpi=150, bbox_inches='tight')
    plt.close()
    print("\nğŸ’¾ ä¿å­˜: hypothesis1_seasonal_correlation.png")
    
    # ã‚°ãƒ©ãƒ•2: æœˆåˆ¥æ¨ç§»æ¯”è¼ƒï¼ˆæ¨™æº–åŒ–ï¼‰
    fig, ax = plt.subplots(figsize=(12, 6))
    
    # æ¨™æº–åŒ–ï¼ˆå¹³å‡0ã€æ¨™æº–åå·®1ï¼‰
    df['hokkaido_std'] = (df['hokkaido'] - df['hokkaido'].mean()) / df['hokkaido'].std()
    df['okinawa_std'] = (df['okinawa'] - df['okinawa'].mean()) / df['okinawa'].std()
    df['tokyo_std'] = (df['tokyo'] - df['tokyo'].mean()) / df['tokyo'].std()
    
    months_label = [f"{int(m)}æœˆ" for m in df['month']]
    
    ax.plot(months_label, df['hokkaido_std'], marker='o', linewidth=2, label='åŒ—æµ·é“', color='blue')
    ax.plot(months_label, df['okinawa_std'], marker='s', linewidth=2, label='æ²–ç¸„çœŒ', color='coral')
    ax.plot(months_label, df['tokyo_std'], marker='^', linewidth=2, label='æ±äº¬éƒ½', color='green')
    
    ax.axhline(0, color='gray', linestyle='--', linewidth=1, alpha=0.5)
    ax.set_xlabel('æœˆ', fontsize=12)
    ax.set_ylabel('æ¨™æº–åŒ–å®¿æ³Šæ•°ï¼ˆå¹³å‡0, SD=1ï¼‰', fontsize=12)
    ax.set_title('æ¨™æº–åŒ–ã—ãŸæœˆåˆ¥å®¿æ³Šæ•°æ¨ç§» - å­£ç¯€ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¯”è¼ƒ', fontsize=13, fontweight='bold')
    ax.legend(fontsize=11)
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('hypothesis1_standardized_trend.png', dpi=150, bbox_inches='tight')
    plt.close()
    print("ğŸ’¾ ä¿å­˜: hypothesis1_standardized_trend.png")
    
    # çµè«–
    print("\nã€ä»®èª¬1ã®æ¤œè¨¼çµæœã€‘")
    if corr_hokkaido_okinawa < -0.3:
        print("âœ… ä»®èª¬æ”¯æŒ: åŒ—æµ·é“ã¨æ²–ç¸„ã¯æ˜ç¢ºãªé€†ç›¸é–¢ï¼ˆè£œå®Œé–¢ä¿‚ï¼‰ã‚’ç¤ºã™")
        print("   â†’ ã€Œå†¬ã®åŒ—æµ·é“ã€å¤ã®æ²–ç¸„ã€ã¨ã„ã†å­£ç¯€è£œå®Œå‹è¦³å…‰æˆ¦ç•¥ãŒæœ‰åŠ¹")
    elif corr_hokkaido_okinawa < 0:
        print("âš ï¸ å¼±ã„é€†ç›¸é–¢: ä¸€éƒ¨ã®æœˆã§è£œå®Œé–¢ä¿‚ãŒè¦‹ã‚‰ã‚Œã‚‹")
    else:
        print("âŒ ä»®èª¬ä¸æ”¯æŒ: é€†ç›¸é–¢ã¯ç¢ºèªã§ããš")
    
    print(f"\n   åŒ—æµ·é“ã®å¤‰å‹•ãƒªã‚¹ã‚¯ã¯æ±äº¬éƒ½ã®{cv_hokkaido/cv_tokyo:.2f}å€")
    print(f"   â†’ åŒ—æµ·é“ã¯æ°—å€™å¤‰å‹•ãƒ»é›ªä¸è¶³ãƒªã‚¹ã‚¯ã«ç‰¹ã«è„†å¼±")


# ==========================================
# ä»®èª¬2: å›½ç±åˆ¥ã®åœ°åŸŸé¸å¥½ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
# ==========================================

def hypothesis2_nationality_preference(conn):
    """ä»®èª¬2: å›½ç±åˆ¥ã®åœ°åŸŸåˆ†æ•£åº¦åˆ†æ"""
    
    print("\n" + "="*70)
    print("ğŸ”¬ ä»®èª¬2: å›½ç±åˆ¥ã®åœ°åŸŸé¸å¥½ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ")
    print("="*70)
    
    placeholders = ','.join('?' * len(EXCLUDE_CATEGORIES))
    
    # åˆ†æå¯¾è±¡å›½ç±
    target_nationalities = ['ä¸­å›½', 'éŸ“å›½', 'å°æ¹¾', 'ç±³å›½', 'ã‚ªãƒ¼ã‚¹ãƒˆãƒ©ãƒªã‚¢', 'è‹±å›½']
    
    results = []
    
    for nationality in target_nationalities:
        params = EXCLUDE_CATEGORIES + [nationality]
        query = f'''
            SELECT prefecture, SUM(value) as total
            FROM tourism_data
            WHERE nationality NOT IN ({placeholders})
                  AND nationality = ?
                  AND month > 0
            GROUP BY prefecture
            ORDER BY total DESC
        '''
        df = pd.read_sql(query, conn, params=params)
        
        # ã‚·ã‚§ã‚¢è¨ˆç®—
        df['share'] = df['total'] / df['total'].sum()
        
        # ãƒãƒ¼ãƒ•ã‚£ãƒ³ãƒ€ãƒ¼ãƒ«æŒ‡æ•° (HHI): 0ã«è¿‘ã„=åˆ†æ•£ã€1ã«è¿‘ã„=é›†ä¸­
        hhi = (df['share'] ** 2).sum()
        
        # ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ãƒ«ãƒ¼ãƒˆ(æ±äº¬ãƒ»å¤§é˜ªãƒ»äº¬éƒ½)ä¾å­˜åº¦
        golden_route_share = df[df['prefecture'].isin(['æ±äº¬éƒ½', 'å¤§é˜ªåºœ', 'äº¬éƒ½åºœ'])]['share'].sum()
        
        # ãƒˆãƒƒãƒ—5ã®ã‚·ã‚§ã‚¢
        top5_share = df.head(5)['share'].sum()
        
        results.append({
            'nationality': nationality,
            'hhi': hhi,
            'golden_route_share': golden_route_share,
            'top5_share': top5_share,
            'top1': df.iloc[0]['prefecture'],
            'top1_share': df.iloc[0]['share']
        })
    
    results_df = pd.DataFrame(results)
    
    # çµæœè¡¨ç¤º
    print(f"\nã€å›½ç±åˆ¥ã®åœ°åŸŸé›†ä¸­åº¦ã€‘")
    print(f"{'å›½ç±':<15} {'HHI':>8} {'GRä¾å­˜åº¦':>10} {'Top5ä¾å­˜åº¦':>12} {'æœ€å¤šè¨ªå•åœ°':<10} {'ã‚·ã‚§ã‚¢':>8}")
    print("-" * 70)
    
    for _, row in results_df.iterrows():
        print(f"{row['nationality']:<15} {row['hhi']:>8.3f} {row['golden_route_share']:>9.1%} "
              f"{row['top5_share']:>11.1%} {row['top1']:<10} {row['top1_share']:>7.1%}")
    
    print("\nã€æŒ‡æ¨™ã®è§£é‡ˆã€‘")
    print("  HHI (ãƒãƒ¼ãƒ•ã‚£ãƒ³ãƒ€ãƒ¼ãƒ«æŒ‡æ•°): åœ°åŸŸé›†ä¸­åº¦ (ä½ã„=åˆ†æ•£çš„, é«˜ã„=é›†ä¸­çš„)")
    print("  GRä¾å­˜åº¦: ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ãƒ«ãƒ¼ãƒˆ(æ±äº¬ãƒ»å¤§é˜ªãƒ»äº¬éƒ½)ã¸ã®ä¾å­˜åº¦")
    print("  Top5ä¾å­˜åº¦: ä¸Šä½5éƒ½é“åºœçœŒã¸ã®ä¾å­˜åº¦")
    
    # ã‚°ãƒ©ãƒ•1: HHIæ¯”è¼ƒ
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    # HHI
    axes[0, 0].barh(results_df['nationality'], results_df['hhi'], 
                    color=['#E74C3C' if x > 0.15 else '#3498DB' for x in results_df['hhi']])
    axes[0, 0].set_xlabel('HHI (åœ°åŸŸé›†ä¸­åº¦)', fontsize=11)
    axes[0, 0].set_title('å›½ç±åˆ¥ åœ°åŸŸé›†ä¸­åº¦ (HHI)', fontsize=12, fontweight='bold')
    axes[0, 0].axvline(0.15, color='red', linestyle='--', linewidth=1, alpha=0.5, label='é«˜é›†ä¸­ã®é–¾å€¤')
    axes[0, 0].legend()
    axes[0, 0].grid(axis='x', alpha=0.3)
    
    # ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ãƒ«ãƒ¼ãƒˆä¾å­˜åº¦
    axes[0, 1].barh(results_df['nationality'], results_df['golden_route_share'], 
                    color='#F39C12')
    axes[0, 1].set_xlabel('ã‚·ã‚§ã‚¢', fontsize=11)
    axes[0, 1].set_title('ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ãƒ«ãƒ¼ãƒˆä¾å­˜åº¦', fontsize=12, fontweight='bold')
    axes[0, 1].xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:.0%}'))
    axes[0, 1].grid(axis='x', alpha=0.3)
    
    # Top5ä¾å­˜åº¦
    axes[1, 0].barh(results_df['nationality'], results_df['top5_share'], 
                    color='#9B59B6')
    axes[1, 0].set_xlabel('ã‚·ã‚§ã‚¢', fontsize=11)
    axes[1, 0].set_title('ä¸Šä½5éƒ½é“åºœçœŒä¾å­˜åº¦', fontsize=12, fontweight='bold')
    axes[1, 0].xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x:.0%}'))
    axes[1, 0].grid(axis='x', alpha=0.3)
    
    # æ•£å¸ƒå›³: HHI vs ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ãƒ«ãƒ¼ãƒˆä¾å­˜åº¦
    axes[1, 1].scatter(results_df['hhi'], results_df['golden_route_share'], 
                       s=200, alpha=0.6, c=range(len(results_df)), cmap='Set2')
    
    for _, row in results_df.iterrows():
        axes[1, 1].annotate(row['nationality'], 
                           (row['hhi'], row['golden_route_share']),
                           fontsize=9, ha='center', va='bottom')
    
    axes[1, 1].set_xlabel('HHI (åœ°åŸŸé›†ä¸­åº¦)', fontsize=11)
    axes[1, 1].set_ylabel('ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ãƒ«ãƒ¼ãƒˆä¾å­˜åº¦', fontsize=11)
    axes[1, 1].set_title('é›†ä¸­åº¦ vs GRä¾å­˜åº¦ã®é–¢ä¿‚', fontsize=12, fontweight='bold')
    axes[1, 1].yaxis.set_major_formatter(plt.FuncFormatter(lambda y, p: f'{y:.0%}'))
    axes[1, 1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('hypothesis2_nationality_concentration.png', dpi=150, bbox_inches='tight')
    plt.close()
    print("\nğŸ’¾ ä¿å­˜: hypothesis2_nationality_concentration.png")
    
    # ã‚°ãƒ©ãƒ•2: å›½ç±åˆ¥ãƒˆãƒƒãƒ—10éƒ½é“åºœçœŒãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
    fig, ax = plt.subplots(figsize=(14, 8))
    
    heatmap_data = []
    for nationality in target_nationalities:
        params = EXCLUDE_CATEGORIES + [nationality]
        query = f'''
            SELECT prefecture, SUM(value) as total
            FROM tourism_data
            WHERE nationality NOT IN ({placeholders})
                  AND nationality = ?
                  AND month > 0
            GROUP BY prefecture
            ORDER BY total DESC
            LIMIT 10
        '''
        df = pd.read_sql(query, conn, params=params)
        df['share'] = df['total'] / df['total'].sum() * 100
        
        # å›½ç±ã”ã¨ã®ãƒˆãƒƒãƒ—10ã‚’è¾æ›¸åŒ–
        pref_dict = dict(zip(df['prefecture'], df['share']))
        heatmap_data.append(pref_dict)
    
    # å…¨å›½ç±ã®ãƒˆãƒƒãƒ—10éƒ½é“åºœçœŒãƒªã‚¹ãƒˆã‚’ä½œæˆ
    all_prefs = set()
    for data in heatmap_data:
        all_prefs.update(data.keys())
    all_prefs = sorted(all_prefs, key=lambda x: sum(d.get(x, 0) for d in heatmap_data), reverse=True)[:15]
    
    # ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ä½œæˆ
    matrix = []
    for data in heatmap_data:
        matrix.append([data.get(pref, 0) for pref in all_prefs])
    
    sns.heatmap(matrix, annot=True, fmt='.1f', cmap='YlOrRd',
                xticklabels=all_prefs, yticklabels=target_nationalities,
                linewidths=0.5, cbar_kws={'label': 'ã‚·ã‚§ã‚¢ (%)'})
    
    ax.set_title('å›½ç±åˆ¥ éƒ½é“åºœçœŒé¸å¥½ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆä¸Šä½15åœ°åŸŸï¼‰', fontsize=13, fontweight='bold', pad=15)
    ax.set_xlabel('éƒ½é“åºœçœŒ', fontsize=11)
    ax.set_ylabel('å›½ç±', fontsize=11)
    
    plt.tight_layout()
    plt.savefig('hypothesis2_nationality_preference_heatmap.png', dpi=150, bbox_inches='tight')
    plt.close()
    print("ğŸ’¾ ä¿å­˜: hypothesis2_nationality_preference_heatmap.png")
    
    # çµè«–
    print("\nã€ä»®èª¬2ã®æ¤œè¨¼çµæœã€‘")
    
    asia_hhi = results_df[results_df['nationality'].isin(['ä¸­å›½', 'éŸ“å›½', 'å°æ¹¾'])]['hhi'].mean()
    western_hhi = results_df[results_df['nationality'].isin(['ç±³å›½', 'ã‚ªãƒ¼ã‚¹ãƒˆãƒ©ãƒªã‚¢', 'è‹±å›½'])]['hhi'].mean()
    
    print(f"\n  ã‚¢ã‚¸ã‚¢åœå¹³å‡HHI: {asia_hhi:.3f}")
    print(f"  æ¬§ç±³åœå¹³å‡HHI: {western_hhi:.3f}")
    print(f"  å·®: {(western_hhi - asia_hhi):.3f}")
    
    if western_hhi < asia_hhi:
        print("\nâœ… ä»®èª¬æ”¯æŒ: æ¬§ç±³åœã¯åœ°æ–¹åˆ†æ•£åº¦ãŒé«˜ã„")
        print("   â†’ åœ°æ–¹å‰µç”Ÿã«ã¯æ¬§ç±³å®¢èª˜è‡´ãŒåŠ¹æœçš„")
    else:
        print("\nâŒ ä»®èª¬ä¸æ”¯æŒ: ã‚¢ã‚¸ã‚¢åœã®æ–¹ãŒåˆ†æ•£çš„")
    
    # è¿½åŠ åˆ†æ: éŸ“å›½ã®ç‰¹å¾´
    korea_gr = results_df[results_df['nationality'] == 'éŸ“å›½']['golden_route_share'].values[0]
    print(f"\nã€ç‰¹è¨˜äº‹é …ã€‘")
    print(f"  éŸ“å›½ã®GRä¾å­˜åº¦: {korea_gr:.1%}")
    print(f"  â†’ {'åœ°æ–¹åˆ†æ•£å‹' if korea_gr < 0.5 else 'GRé›†ä¸­å‹'}")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    conn = connect_db()
    
    try:
        # æ—¢å­˜åˆ†æ
        analyze_monthly_summary(conn)
        analyze_monthly_trend(conn)
        analyze_monthly_prefecture_ranking(conn)
        analyze_specific_month(conn, 12)
        
        # å€‹åˆ¥éƒ½é“åºœçœŒ
        analyze_prefecture_trend(conn, 'æ±äº¬éƒ½')
        analyze_prefecture_trend(conn, 'åŒ—æµ·é“')
        analyze_prefecture_trend(conn, 'æ²–ç¸„çœŒ')
        
        # ä»®èª¬æ¤œè¨¼
        hypothesis1_seasonal_correlation(conn)
        hypothesis2_nationality_preference(conn)
        
        print("\n" + "="*60)
        print("âœ… å…¨åˆ†æå®Œäº†")
        print("="*60)
        
    finally:
        conn.close()

if __name__ == '__main__':
    main()